{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ab61ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-31 20:47:21.377784: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/naman/anaconda3/envs/virtual_regression/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-05-31 20:47:21.378008: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/naman/anaconda3/envs/virtual_regression/lib/python3.10/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.6.0 and strictly below 2.9.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.9.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d2eeb0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2b2b1485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(813, 64, 64, 3)\n",
      "(813, 1)\n",
      "(64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "# Imgae Class 1\n",
    "import glob\n",
    "import cv2 as cv\n",
    "\n",
    "path = glob.glob(\"/home/naman/Dataset6/DYK_CROPPED/*.bmp\")\n",
    "cv_img_1 = []\n",
    "for img in path:\n",
    "    n = cv.imread(img)\n",
    "    n = cv.resize(n, (pix, pix))\n",
    "    cv_img_1.append(n)\n",
    "cv_img_1 = np.array(cv_img_1)\n",
    "#cv_img_1= cv_img_1.reshape(cv_img_1.shape[0], 3, 32,32)\n",
    "print(cv_img_1.shape)\n",
    "\n",
    "Y_1 = np.zeros(cv_img_1.shape[0]).reshape(-1,1)\n",
    "print(Y_1.shape)\n",
    "print(cv_img_1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8f923bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825, 64, 64, 3)\n",
      "(825, 1)\n"
     ]
    }
   ],
   "source": [
    "path = glob.glob(\"/home/naman/Dataset6/KOIL_CROPPED/*.bmp\")\n",
    "cv_img_2 = []\n",
    "for img in path:\n",
    "    n = cv.imread(img)\n",
    "    n = cv.resize(n, (pix, pix))\n",
    "    cv_img_2.append(n)\n",
    "cv_img_2 = np.array(cv_img_2)\n",
    "#cv_img_2= cv_img_2.reshape(cv_img_2.shape[0], 3, 32,32)\n",
    "print(cv_img_2.shape)\n",
    "\n",
    "\n",
    "Y_2 = 1*np.ones(cv_img_2.shape[0]).reshape(-1,1)\n",
    "print(Y_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d0ea5094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(793, 64, 64, 3)\n",
      "(793, 1)\n"
     ]
    }
   ],
   "source": [
    "path = glob.glob(\"/home/naman/Dataset6/META_CROPPED/*.bmp\")\n",
    "cv_img_3 = []\n",
    "for img in path:\n",
    "    n = cv.imread(img)\n",
    "    n = cv.resize(n, (pix, pix))\n",
    "    cv_img_3.append(n)\n",
    "cv_img_3 = np.array(cv_img_3)\n",
    "#cv_img_3= cv_img_3.reshape(cv_img_3.shape[0], 3, 32,32)\n",
    "print(cv_img_3.shape)\n",
    "\n",
    "Y_3 = 2*np.ones(cv_img_3.shape[0]).reshape(-1,1)\n",
    "print(Y_3.shape)\n",
    "#print(Y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dfd68ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(787, 64, 64, 3)\n",
      "(787, 1)\n"
     ]
    }
   ],
   "source": [
    "path = glob.glob(\"/home/naman/Dataset6/PARA_CROPPED/*.bmp\")\n",
    "cv_img_4 = []\n",
    "for img in path:\n",
    "    n = cv.imread(img)\n",
    "    n = cv2.resize(n, (pix, pix))\n",
    "    cv_img_4.append(n)\n",
    "cv_img_4 = np.array(cv_img_4)\n",
    "#cv_img_4= cv_img_4.reshape(cv_img_4.shape[0], 3, 32,32)\n",
    "print(cv_img_4.shape)\n",
    "\n",
    "\n",
    "Y_4 = 3*np.ones(cv_img_4.shape[0]).reshape(-1,1)\n",
    "print(Y_4.shape)\n",
    "#print(Y_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6826e1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(831, 64, 64, 3)\n",
      "(831, 1)\n"
     ]
    }
   ],
   "source": [
    "path = glob.glob(\"/home/naman/Dataset6/SUP_CROPPED/*.bmp\")\n",
    "cv_img_5 = []\n",
    "for img in path:\n",
    "    n = cv.imread(img)\n",
    "    n = cv2.resize(n, (pix, pix))\n",
    "    cv_img_5.append(n)\n",
    "cv_img_5 = np.array(cv_img_5)\n",
    "#cv_img_5= cv_img_5.reshape(cv_img_5.shape[0],3, 32,32)\n",
    "print(cv_img_5.shape)\n",
    "\n",
    "\n",
    "Y_5 = 4*np.ones(cv_img_5.shape[0]).reshape(-1,1)\n",
    "print(Y_5.shape)\n",
    "#print(Y_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bcf9bd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4049, 1)\n",
      "(4049, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "X_data = np.append(cv_img_1, cv_img_2, axis = 0)\n",
    "X_data = np.append(X_data, cv_img_3, axis = 0)\n",
    "X_data = np.append(X_data, cv_img_4, axis = 0)\n",
    "X_data = np.append(X_data, cv_img_5, axis = 0)\n",
    "#X_data = np.append(X_data, cv_img_6, axis = 0)\n",
    "#X_data = np.append(X_data, cv_img_7, axis = 0)\n",
    "\n",
    "Y_data = np.append(Y_1, Y_2, axis = 0)\n",
    "Y_data = np.append(Y_data, Y_3, axis = 0)\n",
    "Y_data = np.append(Y_data, Y_4, axis = 0)\n",
    "Y_data = np.append(Y_data, Y_5, axis = 0)\n",
    "#Y_data = np.append(Y_data, Y_6, axis = 0)\n",
    "#Y_data = np.append(Y_data, Y_7, axis = 0)\n",
    "\n",
    "print(Y_data.shape)\n",
    "print(X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a98b21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f72c9ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: (3239, 64, 64, 3) - y_train: (3239, 1)\n",
      "x_test: (810, 64, 64, 3) - y_test: (810, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_train: {x_train.shape} - y_train: {y_train.shape}\")\n",
    "print(f\"x_test: {x_test.shape} - y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fe34d91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(72, 72),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3ec84100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "083b5267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 63.5, 63.5, -0.5)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ea02470e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 200\n",
    "image_size = 72  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "584037ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "50fd6cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 72 X 72\n",
      "Patch size: 6 X 6\n",
      "Patches per image: 144\n",
      "Elements per patch: 108\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 144 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a9802da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "169b5cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "030df21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 100\n",
    "input_shape = (pix, pix, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a2816bbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 172s 13s/step - loss: 7.2499 - accuracy: 0.3890 - top-2-accuracy: 0.6357 - val_loss: 1.2764 - val_accuracy: 0.6327 - val_top-2-accuracy: 0.8148\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 160s 13s/step - loss: 1.3187 - accuracy: 0.5959 - top-2-accuracy: 0.7962 - val_loss: 0.7147 - val_accuracy: 0.7469 - val_top-2-accuracy: 0.9074\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 159s 13s/step - loss: 0.9720 - accuracy: 0.6624 - top-2-accuracy: 0.8617 - val_loss: 0.6921 - val_accuracy: 0.7191 - val_top-2-accuracy: 0.9074\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 158s 13s/step - loss: 0.8431 - accuracy: 0.6991 - top-2-accuracy: 0.8868 - val_loss: 0.5988 - val_accuracy: 0.8056 - val_top-2-accuracy: 0.9352\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 163s 14s/step - loss: 0.7342 - accuracy: 0.7369 - top-2-accuracy: 0.8943 - val_loss: 0.5124 - val_accuracy: 0.8364 - val_top-2-accuracy: 0.9383\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 161s 13s/step - loss: 0.6699 - accuracy: 0.7588 - top-2-accuracy: 0.9111 - val_loss: 0.4560 - val_accuracy: 0.8519 - val_top-2-accuracy: 0.9660\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 168s 14s/step - loss: 0.6362 - accuracy: 0.7780 - top-2-accuracy: 0.9208 - val_loss: 0.4486 - val_accuracy: 0.8333 - val_top-2-accuracy: 0.9537\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 157s 13s/step - loss: 0.5512 - accuracy: 0.7993 - top-2-accuracy: 0.9328 - val_loss: 0.4672 - val_accuracy: 0.8210 - val_top-2-accuracy: 0.9753\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 155s 13s/step - loss: 0.5203 - accuracy: 0.8182 - top-2-accuracy: 0.9424 - val_loss: 0.3471 - val_accuracy: 0.8858 - val_top-2-accuracy: 0.9846\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 164s 14s/step - loss: 0.4505 - accuracy: 0.8456 - top-2-accuracy: 0.9513 - val_loss: 0.3080 - val_accuracy: 0.8951 - val_top-2-accuracy: 0.9753\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 166s 14s/step - loss: 0.4540 - accuracy: 0.8453 - top-2-accuracy: 0.9533 - val_loss: 0.3330 - val_accuracy: 0.8827 - val_top-2-accuracy: 0.9784\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 157s 13s/step - loss: 0.4632 - accuracy: 0.8446 - top-2-accuracy: 0.9523 - val_loss: 0.3030 - val_accuracy: 0.8920 - val_top-2-accuracy: 0.9815\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 165s 14s/step - loss: 0.3787 - accuracy: 0.8707 - top-2-accuracy: 0.9595 - val_loss: 0.2712 - val_accuracy: 0.9167 - val_top-2-accuracy: 0.9846\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 165s 14s/step - loss: 0.3434 - accuracy: 0.8803 - top-2-accuracy: 0.9684 - val_loss: 0.2235 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9877\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 163s 14s/step - loss: 0.3151 - accuracy: 0.8916 - top-2-accuracy: 0.9698 - val_loss: 0.2124 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9877\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 158s 13s/step - loss: 0.3103 - accuracy: 0.8899 - top-2-accuracy: 0.9743 - val_loss: 0.2215 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9907\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 161s 13s/step - loss: 0.2839 - accuracy: 0.9005 - top-2-accuracy: 0.9770 - val_loss: 0.2488 - val_accuracy: 0.9074 - val_top-2-accuracy: 0.9877\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 168s 14s/step - loss: 0.3103 - accuracy: 0.8943 - top-2-accuracy: 0.9739 - val_loss: 0.2283 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9815\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 154s 13s/step - loss: 0.2813 - accuracy: 0.9015 - top-2-accuracy: 0.9763 - val_loss: 0.2024 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9938\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 159s 13s/step - loss: 0.2550 - accuracy: 0.9087 - top-2-accuracy: 0.9787 - val_loss: 0.2551 - val_accuracy: 0.9012 - val_top-2-accuracy: 0.9846\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 164s 14s/step - loss: 0.2155 - accuracy: 0.9238 - top-2-accuracy: 0.9791 - val_loss: 0.1932 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9877\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 151s 13s/step - loss: 0.2112 - accuracy: 0.9249 - top-2-accuracy: 0.9852 - val_loss: 0.1870 - val_accuracy: 0.9290 - val_top-2-accuracy: 0.9877\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 157s 13s/step - loss: 0.2242 - accuracy: 0.9218 - top-2-accuracy: 0.9852 - val_loss: 0.2021 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9907\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 163s 13s/step - loss: 0.2036 - accuracy: 0.9304 - top-2-accuracy: 0.9890 - val_loss: 0.2053 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9846\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 157s 13s/step - loss: 0.1895 - accuracy: 0.9345 - top-2-accuracy: 0.9846 - val_loss: 0.2102 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9907\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 160s 13s/step - loss: 0.2102 - accuracy: 0.9290 - top-2-accuracy: 0.9825 - val_loss: 0.1641 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9907\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 158s 13s/step - loss: 0.1649 - accuracy: 0.9396 - top-2-accuracy: 0.9907 - val_loss: 0.1773 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9907\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 161s 13s/step - loss: 0.1468 - accuracy: 0.9509 - top-2-accuracy: 0.9931 - val_loss: 0.2141 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9815\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 154s 13s/step - loss: 0.1680 - accuracy: 0.9393 - top-2-accuracy: 0.9904 - val_loss: 0.1424 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9907\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 151s 13s/step - loss: 0.1472 - accuracy: 0.9482 - top-2-accuracy: 0.9918 - val_loss: 0.2046 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9938\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 150s 12s/step - loss: 0.1674 - accuracy: 0.9413 - top-2-accuracy: 0.9918 - val_loss: 0.2219 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9907\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 161s 13s/step - loss: 0.1863 - accuracy: 0.9362 - top-2-accuracy: 0.9873 - val_loss: 0.1815 - val_accuracy: 0.9383 - val_top-2-accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 169s 14s/step - loss: 0.1534 - accuracy: 0.9448 - top-2-accuracy: 0.9901 - val_loss: 0.1965 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9938\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 160s 13s/step - loss: 0.1322 - accuracy: 0.9520 - top-2-accuracy: 0.9935 - val_loss: 0.2178 - val_accuracy: 0.9228 - val_top-2-accuracy: 0.9846\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 160s 13s/step - loss: 0.1324 - accuracy: 0.9588 - top-2-accuracy: 0.9935 - val_loss: 0.1955 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9907\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 175s 15s/step - loss: 0.1229 - accuracy: 0.9581 - top-2-accuracy: 0.9945 - val_loss: 0.3148 - val_accuracy: 0.9167 - val_top-2-accuracy: 0.9938\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 265s 22s/step - loss: 0.1938 - accuracy: 0.9362 - top-2-accuracy: 0.9863 - val_loss: 0.1861 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9969\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 267s 22s/step - loss: 0.1350 - accuracy: 0.9544 - top-2-accuracy: 0.9894 - val_loss: 0.1680 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9877\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 262s 22s/step - loss: 0.1354 - accuracy: 0.9516 - top-2-accuracy: 0.9918 - val_loss: 0.1910 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9938\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 261s 21s/step - loss: 0.1147 - accuracy: 0.9599 - top-2-accuracy: 0.9955 - val_loss: 0.1948 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9907\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 179s 14s/step - loss: 0.1018 - accuracy: 0.9664 - top-2-accuracy: 0.9952 - val_loss: 0.1314 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9969\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 164s 14s/step - loss: 0.0838 - accuracy: 0.9684 - top-2-accuracy: 0.9955 - val_loss: 0.1747 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9969\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 159s 13s/step - loss: 0.0665 - accuracy: 0.9780 - top-2-accuracy: 0.9983 - val_loss: 0.1609 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9969\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 158s 13s/step - loss: 0.0590 - accuracy: 0.9784 - top-2-accuracy: 0.9990 - val_loss: 0.1613 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9969\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 160s 13s/step - loss: 0.0709 - accuracy: 0.9784 - top-2-accuracy: 0.9973 - val_loss: 0.1841 - val_accuracy: 0.9537 - val_top-2-accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 164s 14s/step - loss: 0.0651 - accuracy: 0.9774 - top-2-accuracy: 0.9976 - val_loss: 0.1363 - val_accuracy: 0.9660 - val_top-2-accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 160s 13s/step - loss: 0.0700 - accuracy: 0.9760 - top-2-accuracy: 0.9990 - val_loss: 0.1939 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 163s 14s/step - loss: 0.0811 - accuracy: 0.9712 - top-2-accuracy: 0.9949 - val_loss: 0.1638 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9969\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 160s 13s/step - loss: 0.0869 - accuracy: 0.9712 - top-2-accuracy: 0.9976 - val_loss: 0.2057 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 164s 14s/step - loss: 0.0732 - accuracy: 0.9719 - top-2-accuracy: 0.9983 - val_loss: 0.1952 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9938\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 164s 14s/step - loss: 0.0855 - accuracy: 0.9743 - top-2-accuracy: 0.9949 - val_loss: 0.1489 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9907\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 162s 14s/step - loss: 0.0884 - accuracy: 0.9664 - top-2-accuracy: 0.9966 - val_loss: 0.1560 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9969\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 161s 13s/step - loss: 0.0793 - accuracy: 0.9739 - top-2-accuracy: 0.9962 - val_loss: 0.2052 - val_accuracy: 0.9506 - val_top-2-accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 163s 14s/step - loss: 0.0664 - accuracy: 0.9767 - top-2-accuracy: 0.9973 - val_loss: 0.1738 - val_accuracy: 0.9599 - val_top-2-accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 164s 14s/step - loss: 0.0600 - accuracy: 0.9784 - top-2-accuracy: 0.9990 - val_loss: 0.1819 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9938\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 164s 14s/step - loss: 0.0973 - accuracy: 0.9736 - top-2-accuracy: 0.9952 - val_loss: 0.1620 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9969\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 161s 13s/step - loss: 0.0648 - accuracy: 0.9780 - top-2-accuracy: 0.9976 - val_loss: 0.1493 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9938\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 156s 13s/step - loss: 0.0756 - accuracy: 0.9760 - top-2-accuracy: 0.9983 - val_loss: 0.1528 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9938\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 164s 14s/step - loss: 0.1047 - accuracy: 0.9671 - top-2-accuracy: 0.9959 - val_loss: 0.2157 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9907\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 138s 11s/step - loss: 0.1110 - accuracy: 0.9626 - top-2-accuracy: 0.9938 - val_loss: 0.1520 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9907\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 114s 9s/step - loss: 0.0747 - accuracy: 0.9746 - top-2-accuracy: 0.9983 - val_loss: 0.1716 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9969\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 115s 10s/step - loss: 0.0558 - accuracy: 0.9835 - top-2-accuracy: 0.9997 - val_loss: 0.1208 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9969\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 115s 10s/step - loss: 0.0496 - accuracy: 0.9846 - top-2-accuracy: 0.9976 - val_loss: 0.2320 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9907\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 115s 10s/step - loss: 0.0715 - accuracy: 0.9794 - top-2-accuracy: 0.9979 - val_loss: 0.1780 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9969\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 115s 10s/step - loss: 0.0544 - accuracy: 0.9825 - top-2-accuracy: 0.9986 - val_loss: 0.2006 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9938\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 115s 10s/step - loss: 0.0794 - accuracy: 0.9715 - top-2-accuracy: 0.9973 - val_loss: 0.2289 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9938\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 115s 10s/step - loss: 0.0656 - accuracy: 0.9777 - top-2-accuracy: 0.9983 - val_loss: 0.1519 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9907\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 114s 9s/step - loss: 0.0639 - accuracy: 0.9760 - top-2-accuracy: 0.9983 - val_loss: 0.1546 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9938\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 115s 10s/step - loss: 0.0891 - accuracy: 0.9750 - top-2-accuracy: 0.9966 - val_loss: 0.1951 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 115s 10s/step - loss: 0.0994 - accuracy: 0.9681 - top-2-accuracy: 0.9949 - val_loss: 0.2109 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9907\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 140s 12s/step - loss: 0.0643 - accuracy: 0.9767 - top-2-accuracy: 0.9962 - val_loss: 0.2004 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9969\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 165s 14s/step - loss: 0.0428 - accuracy: 0.9856 - top-2-accuracy: 0.9990 - val_loss: 0.1692 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9907\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 170s 14s/step - loss: 0.0509 - accuracy: 0.9822 - top-2-accuracy: 0.9986 - val_loss: 0.1876 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9969\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 166s 14s/step - loss: 0.0380 - accuracy: 0.9887 - top-2-accuracy: 1.0000 - val_loss: 0.2107 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9938\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 159s 13s/step - loss: 0.0622 - accuracy: 0.9801 - top-2-accuracy: 0.9990 - val_loss: 0.1497 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 164s 14s/step - loss: 0.0451 - accuracy: 0.9835 - top-2-accuracy: 0.9986 - val_loss: 0.2437 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9969\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 161s 13s/step - loss: 0.0395 - accuracy: 0.9887 - top-2-accuracy: 0.9979 - val_loss: 0.1753 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9969\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 162s 14s/step - loss: 0.0423 - accuracy: 0.9839 - top-2-accuracy: 0.9997 - val_loss: 0.2401 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9938\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 163s 14s/step - loss: 0.0361 - accuracy: 0.9870 - top-2-accuracy: 0.9986 - val_loss: 0.2905 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9938\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 165s 14s/step - loss: 0.0657 - accuracy: 0.9780 - top-2-accuracy: 0.9973 - val_loss: 0.2685 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9877\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 163s 14s/step - loss: 0.0709 - accuracy: 0.9760 - top-2-accuracy: 0.9979 - val_loss: 0.2082 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 165s 14s/step - loss: 0.0613 - accuracy: 0.9822 - top-2-accuracy: 0.9979 - val_loss: 0.1796 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9938\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 167s 14s/step - loss: 0.0474 - accuracy: 0.9808 - top-2-accuracy: 0.9997 - val_loss: 0.2116 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 162s 13s/step - loss: 0.0316 - accuracy: 0.9897 - top-2-accuracy: 1.0000 - val_loss: 0.2182 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9938\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 162s 13s/step - loss: 0.0562 - accuracy: 0.9804 - top-2-accuracy: 0.9979 - val_loss: 0.1598 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9969\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 161s 13s/step - loss: 0.0482 - accuracy: 0.9856 - top-2-accuracy: 0.9983 - val_loss: 0.1904 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 169s 14s/step - loss: 0.0453 - accuracy: 0.9849 - top-2-accuracy: 0.9976 - val_loss: 0.1981 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9938\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 160s 13s/step - loss: 0.0548 - accuracy: 0.9835 - top-2-accuracy: 0.9986 - val_loss: 0.1526 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9969\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 160s 13s/step - loss: 0.0405 - accuracy: 0.9859 - top-2-accuracy: 0.9993 - val_loss: 0.2287 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 158s 13s/step - loss: 0.0432 - accuracy: 0.9849 - top-2-accuracy: 0.9997 - val_loss: 0.1895 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9907\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 160s 13s/step - loss: 0.0474 - accuracy: 0.9825 - top-2-accuracy: 0.9993 - val_loss: 0.2176 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9938\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 160s 13s/step - loss: 0.0474 - accuracy: 0.9842 - top-2-accuracy: 0.9983 - val_loss: 0.2478 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9907\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 159s 13s/step - loss: 0.0394 - accuracy: 0.9863 - top-2-accuracy: 0.9993 - val_loss: 0.2399 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9907\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 162s 14s/step - loss: 0.0608 - accuracy: 0.9811 - top-2-accuracy: 0.9979 - val_loss: 0.1724 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9969\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 168s 14s/step - loss: 0.0491 - accuracy: 0.9825 - top-2-accuracy: 0.9993 - val_loss: 0.2721 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9907\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 168s 14s/step - loss: 0.0447 - accuracy: 0.9849 - top-2-accuracy: 0.9997 - val_loss: 0.2825 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9907\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 163s 14s/step - loss: 0.0343 - accuracy: 0.9887 - top-2-accuracy: 0.9997 - val_loss: 0.1949 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9907\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 163s 14s/step - loss: 0.0777 - accuracy: 0.9808 - top-2-accuracy: 0.9979 - val_loss: 0.3773 - val_accuracy: 0.9228 - val_top-2-accuracy: 0.9846\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 146s 12s/step - loss: 0.0616 - accuracy: 0.9777 - top-2-accuracy: 0.9983 - val_loss: 0.2051 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9877\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 126s 11s/step - loss: 0.0518 - accuracy: 0.9835 - top-2-accuracy: 0.9993 - val_loss: 0.1808 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9907\n",
      "26/26 [==============================] - 11s 428ms/step - loss: 0.1404 - accuracy: 0.9580 - top-2-accuracy: 0.9889\n",
      "Test accuracy: 95.8%\n",
      "Test top 2 accuracy: 98.89%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(2, name=\"top-2-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_2_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 2 accuracy: {round(top_2_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e8a0c76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 172s 13s/step - loss: 0.1838 - accuracy: 0.9499 - top-2-accuracy: 0.9925 - val_loss: 0.2701 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9907\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 157s 13s/step - loss: 0.0855 - accuracy: 0.9698 - top-2-accuracy: 0.9952 - val_loss: 0.2480 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9907\n",
      "Epoch 3/100\n",
      "10/12 [========================>.....] - ETA: 24s - loss: 0.0879 - accuracy: 0.9750 - top-2-accuracy: 0.9969"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [128]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#vit_classifier = create_vit_classifier()\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvit_classifier\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [127]\u001b[0m, in \u001b[0;36mrun_experiment\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     15\u001b[0m checkpoint_filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/tmp/checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\n\u001b[1;32m     17\u001b[0m     checkpoint_filepath,\n\u001b[1;32m     18\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     20\u001b[0m     save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(checkpoint_filepath)\n\u001b[1;32m     33\u001b[0m _, accuracy, top_2_accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/virtual_regression/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/virtual_regression/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/virtual_regression/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/virtual_regression/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/virtual_regression/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/virtual_regression/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/virtual_regression/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/virtual_regression/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/virtual_regression/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72ab2019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 71s 5s/step - loss: 5.1676 - accuracy: 0.3945 - top-2-accuracy: 0.6117 - val_loss: 1.0517 - val_accuracy: 0.6389 - val_top-2-accuracy: 0.8086\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 62s 5s/step - loss: 1.1733 - accuracy: 0.6206 - top-2-accuracy: 0.8175 - val_loss: 0.6913 - val_accuracy: 0.7315 - val_top-2-accuracy: 0.8889\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 60s 5s/step - loss: 0.9372 - accuracy: 0.6864 - top-2-accuracy: 0.8662 - val_loss: 0.6268 - val_accuracy: 0.7778 - val_top-2-accuracy: 0.9105\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.7755 - accuracy: 0.7448 - top-2-accuracy: 0.8967 - val_loss: 0.4718 - val_accuracy: 0.8241 - val_top-2-accuracy: 0.9599\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 60s 5s/step - loss: 0.6635 - accuracy: 0.7684 - top-2-accuracy: 0.9211 - val_loss: 0.4246 - val_accuracy: 0.8519 - val_top-2-accuracy: 0.9568\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.5794 - accuracy: 0.8017 - top-2-accuracy: 0.9307 - val_loss: 0.3566 - val_accuracy: 0.8796 - val_top-2-accuracy: 0.9722\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 60s 5s/step - loss: 0.4866 - accuracy: 0.8288 - top-2-accuracy: 0.9489 - val_loss: 0.3422 - val_accuracy: 0.8642 - val_top-2-accuracy: 0.9568\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.4578 - accuracy: 0.8436 - top-2-accuracy: 0.9516 - val_loss: 0.2852 - val_accuracy: 0.9043 - val_top-2-accuracy: 0.9784\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.4249 - accuracy: 0.8559 - top-2-accuracy: 0.9588 - val_loss: 0.2509 - val_accuracy: 0.9167 - val_top-2-accuracy: 0.9846\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.3725 - accuracy: 0.8724 - top-2-accuracy: 0.9660 - val_loss: 0.2802 - val_accuracy: 0.8981 - val_top-2-accuracy: 0.9691\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 60s 5s/step - loss: 0.3660 - accuracy: 0.8738 - top-2-accuracy: 0.9681 - val_loss: 0.2773 - val_accuracy: 0.8765 - val_top-2-accuracy: 0.9753\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.3571 - accuracy: 0.8738 - top-2-accuracy: 0.9681 - val_loss: 0.2298 - val_accuracy: 0.9198 - val_top-2-accuracy: 0.9907\n",
      "Epoch 13/200\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.2974 - accuracy: 0.8971 - top-2-accuracy: 0.9746 - val_loss: 0.2306 - val_accuracy: 0.9167 - val_top-2-accuracy: 0.9907\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 60s 5s/step - loss: 0.2939 - accuracy: 0.9022 - top-2-accuracy: 0.9732 - val_loss: 0.2120 - val_accuracy: 0.9167 - val_top-2-accuracy: 0.9877\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 60s 5s/step - loss: 0.2874 - accuracy: 0.8940 - top-2-accuracy: 0.9743 - val_loss: 0.2012 - val_accuracy: 0.9198 - val_top-2-accuracy: 0.9877\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.2471 - accuracy: 0.9115 - top-2-accuracy: 0.9828 - val_loss: 0.1829 - val_accuracy: 0.9290 - val_top-2-accuracy: 0.9938\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.2377 - accuracy: 0.9211 - top-2-accuracy: 0.9870 - val_loss: 0.2201 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9907\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 61s 5s/step - loss: 0.2177 - accuracy: 0.9187 - top-2-accuracy: 0.9873 - val_loss: 0.1721 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9907\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 60s 5s/step - loss: 0.2098 - accuracy: 0.9280 - top-2-accuracy: 0.9852 - val_loss: 0.1579 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9938\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 60s 5s/step - loss: 0.2164 - accuracy: 0.9266 - top-2-accuracy: 0.9852 - val_loss: 0.1516 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9938\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 62s 5s/step - loss: 0.2203 - accuracy: 0.9177 - top-2-accuracy: 0.9842 - val_loss: 0.1469 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9938\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 64s 5s/step - loss: 0.1764 - accuracy: 0.9362 - top-2-accuracy: 0.9907 - val_loss: 0.1455 - val_accuracy: 0.9444 - val_top-2-accuracy: 1.0000\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 64s 5s/step - loss: 0.1797 - accuracy: 0.9358 - top-2-accuracy: 0.9897 - val_loss: 0.1649 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9877\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 64s 5s/step - loss: 0.1778 - accuracy: 0.9383 - top-2-accuracy: 0.9901 - val_loss: 0.1753 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9907\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 63s 5s/step - loss: 0.1665 - accuracy: 0.9417 - top-2-accuracy: 0.9894 - val_loss: 0.1405 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9969\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 65s 5s/step - loss: 0.1460 - accuracy: 0.9475 - top-2-accuracy: 0.9914 - val_loss: 0.1789 - val_accuracy: 0.9290 - val_top-2-accuracy: 0.9877\n",
      "Epoch 27/200\n",
      "12/12 [==============================] - 87s 7s/step - loss: 0.1504 - accuracy: 0.9465 - top-2-accuracy: 0.9928 - val_loss: 0.1266 - val_accuracy: 0.9537 - val_top-2-accuracy: 1.0000\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.1382 - accuracy: 0.9509 - top-2-accuracy: 0.9931 - val_loss: 0.1731 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9938\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.1250 - accuracy: 0.9564 - top-2-accuracy: 0.9928 - val_loss: 0.1169 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9969\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.1085 - accuracy: 0.9578 - top-2-accuracy: 0.9942 - val_loss: 0.1054 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9938\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.1114 - accuracy: 0.9599 - top-2-accuracy: 0.9938 - val_loss: 0.2228 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9877\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.1309 - accuracy: 0.9557 - top-2-accuracy: 0.9931 - val_loss: 0.1522 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9938\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 90s 7s/step - loss: 0.1409 - accuracy: 0.9537 - top-2-accuracy: 0.9935 - val_loss: 0.2604 - val_accuracy: 0.9136 - val_top-2-accuracy: 0.9722\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.1820 - accuracy: 0.9389 - top-2-accuracy: 0.9877 - val_loss: 0.2306 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9753\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.1170 - accuracy: 0.9578 - top-2-accuracy: 0.9942 - val_loss: 0.1431 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.1157 - accuracy: 0.9623 - top-2-accuracy: 0.9935 - val_loss: 0.2314 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9877\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 93s 8s/step - loss: 0.0958 - accuracy: 0.9664 - top-2-accuracy: 0.9945 - val_loss: 0.0898 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9969\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.0919 - accuracy: 0.9688 - top-2-accuracy: 0.9952 - val_loss: 0.1496 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9938\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.1001 - accuracy: 0.9674 - top-2-accuracy: 0.9973 - val_loss: 0.1936 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9969\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.1134 - accuracy: 0.9636 - top-2-accuracy: 0.9949 - val_loss: 0.2144 - val_accuracy: 0.9290 - val_top-2-accuracy: 0.9877\n",
      "Epoch 41/200\n",
      "12/12 [==============================] - 90s 7s/step - loss: 0.0957 - accuracy: 0.9640 - top-2-accuracy: 0.9955 - val_loss: 0.1433 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9938\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 93s 8s/step - loss: 0.0946 - accuracy: 0.9681 - top-2-accuracy: 0.9962 - val_loss: 0.1244 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9938\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 91s 8s/step - loss: 0.0748 - accuracy: 0.9750 - top-2-accuracy: 0.9979 - val_loss: 0.1931 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9969\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 96s 8s/step - loss: 0.0784 - accuracy: 0.9715 - top-2-accuracy: 0.9976 - val_loss: 0.1789 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9846\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 104s 8s/step - loss: 0.0686 - accuracy: 0.9760 - top-2-accuracy: 0.9986 - val_loss: 0.1110 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9969\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.0913 - accuracy: 0.9678 - top-2-accuracy: 0.9969 - val_loss: 0.1213 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9907\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 115s 9s/step - loss: 0.0652 - accuracy: 0.9756 - top-2-accuracy: 0.9969 - val_loss: 0.1501 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9938\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 112s 9s/step - loss: 0.0696 - accuracy: 0.9739 - top-2-accuracy: 0.9962 - val_loss: 0.1507 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9877\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 85s 7s/step - loss: 0.0665 - accuracy: 0.9739 - top-2-accuracy: 0.9959 - val_loss: 0.1450 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9969\n",
      "Epoch 50/200\n",
      "12/12 [==============================] - 87s 7s/step - loss: 0.0668 - accuracy: 0.9719 - top-2-accuracy: 0.9966 - val_loss: 0.1291 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9938\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 99s 8s/step - loss: 0.0662 - accuracy: 0.9774 - top-2-accuracy: 0.9976 - val_loss: 0.1197 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9938\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 101s 8s/step - loss: 0.0664 - accuracy: 0.9787 - top-2-accuracy: 0.9983 - val_loss: 0.1630 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9938\n",
      "Epoch 53/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0642 - accuracy: 0.9780 - top-2-accuracy: 0.9959 - val_loss: 0.1208 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9938\n",
      "Epoch 54/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0698 - accuracy: 0.9746 - top-2-accuracy: 0.9979 - val_loss: 0.1728 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9969\n",
      "Epoch 55/200\n",
      "12/12 [==============================] - 102s 9s/step - loss: 0.0594 - accuracy: 0.9791 - top-2-accuracy: 0.9973 - val_loss: 0.2334 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9907\n",
      "Epoch 56/200\n",
      "12/12 [==============================] - 101s 8s/step - loss: 0.0799 - accuracy: 0.9746 - top-2-accuracy: 0.9973 - val_loss: 0.1575 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9938\n",
      "Epoch 57/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0889 - accuracy: 0.9732 - top-2-accuracy: 0.9976 - val_loss: 0.1057 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9938\n",
      "Epoch 58/200\n",
      "12/12 [==============================] - 101s 8s/step - loss: 0.0998 - accuracy: 0.9657 - top-2-accuracy: 0.9942 - val_loss: 0.1714 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9938\n",
      "Epoch 59/200\n",
      "12/12 [==============================] - 102s 8s/step - loss: 0.0651 - accuracy: 0.9794 - top-2-accuracy: 0.9986 - val_loss: 0.0749 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9907\n",
      "Epoch 60/200\n",
      "12/12 [==============================] - 101s 8s/step - loss: 0.0673 - accuracy: 0.9784 - top-2-accuracy: 0.9962 - val_loss: 0.0941 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9907\n",
      "Epoch 61/200\n",
      "12/12 [==============================] - 103s 9s/step - loss: 0.0549 - accuracy: 0.9801 - top-2-accuracy: 0.9976 - val_loss: 0.0915 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9938\n",
      "Epoch 62/200\n",
      "12/12 [==============================] - 102s 8s/step - loss: 0.0526 - accuracy: 0.9801 - top-2-accuracy: 0.9986 - val_loss: 0.1582 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 63/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0513 - accuracy: 0.9822 - top-2-accuracy: 0.9976 - val_loss: 0.2101 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9907\n",
      "Epoch 64/200\n",
      "12/12 [==============================] - 100s 8s/step - loss: 0.0528 - accuracy: 0.9763 - top-2-accuracy: 0.9986 - val_loss: 0.1109 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9938\n",
      "Epoch 65/200\n",
      "12/12 [==============================] - 100s 8s/step - loss: 0.0618 - accuracy: 0.9818 - top-2-accuracy: 0.9979 - val_loss: 0.1388 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9846\n",
      "Epoch 66/200\n",
      "12/12 [==============================] - 101s 8s/step - loss: 0.0746 - accuracy: 0.9729 - top-2-accuracy: 0.9962 - val_loss: 0.1353 - val_accuracy: 0.9475 - val_top-2-accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "12/12 [==============================] - 103s 9s/step - loss: 0.0742 - accuracy: 0.9746 - top-2-accuracy: 0.9973 - val_loss: 0.0877 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9938\n",
      "Epoch 68/200\n",
      "12/12 [==============================] - 103s 9s/step - loss: 0.0497 - accuracy: 0.9832 - top-2-accuracy: 0.9976 - val_loss: 0.0929 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9969\n",
      "Epoch 69/200\n",
      "12/12 [==============================] - 102s 9s/step - loss: 0.0425 - accuracy: 0.9849 - top-2-accuracy: 0.9990 - val_loss: 0.1014 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9938\n",
      "Epoch 70/200\n",
      "12/12 [==============================] - 102s 8s/step - loss: 0.0556 - accuracy: 0.9832 - top-2-accuracy: 0.9986 - val_loss: 0.0736 - val_accuracy: 0.9722 - val_top-2-accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "12/12 [==============================] - 92s 8s/step - loss: 0.0433 - accuracy: 0.9866 - top-2-accuracy: 0.9983 - val_loss: 0.1904 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9969\n",
      "Epoch 72/200\n",
      "12/12 [==============================] - 88s 7s/step - loss: 0.0344 - accuracy: 0.9897 - top-2-accuracy: 0.9997 - val_loss: 0.1343 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9969\n",
      "Epoch 73/200\n",
      "12/12 [==============================] - 85s 7s/step - loss: 0.0485 - accuracy: 0.9877 - top-2-accuracy: 0.9986 - val_loss: 0.1149 - val_accuracy: 0.9846 - val_top-2-accuracy: 0.9938\n",
      "Epoch 74/200\n",
      "12/12 [==============================] - 84s 7s/step - loss: 0.0813 - accuracy: 0.9756 - top-2-accuracy: 0.9945 - val_loss: 0.1583 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9907\n",
      "Epoch 75/200\n",
      "12/12 [==============================] - 86s 7s/step - loss: 0.0609 - accuracy: 0.9774 - top-2-accuracy: 0.9969 - val_loss: 0.0929 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9907\n",
      "Epoch 76/200\n",
      "12/12 [==============================] - 88s 7s/step - loss: 0.0466 - accuracy: 0.9852 - top-2-accuracy: 0.9993 - val_loss: 0.1027 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9907\n",
      "Epoch 77/200\n",
      "12/12 [==============================] - 85s 7s/step - loss: 0.0436 - accuracy: 0.9842 - top-2-accuracy: 0.9990 - val_loss: 0.0805 - val_accuracy: 0.9815 - val_top-2-accuracy: 0.9969\n",
      "Epoch 78/200\n",
      "12/12 [==============================] - 84s 7s/step - loss: 0.0354 - accuracy: 0.9890 - top-2-accuracy: 0.9993 - val_loss: 0.1120 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 79/200\n",
      "12/12 [==============================] - 94s 8s/step - loss: 0.0461 - accuracy: 0.9825 - top-2-accuracy: 0.9979 - val_loss: 0.1031 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9969\n",
      "Epoch 80/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0355 - accuracy: 0.9877 - top-2-accuracy: 0.9993 - val_loss: 0.0966 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9938\n",
      "Epoch 81/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0239 - accuracy: 0.9904 - top-2-accuracy: 0.9997 - val_loss: 0.1177 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9907\n",
      "Epoch 82/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0300 - accuracy: 0.9901 - top-2-accuracy: 0.9990 - val_loss: 0.1359 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9969\n",
      "Epoch 83/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0297 - accuracy: 0.9904 - top-2-accuracy: 0.9990 - val_loss: 0.0671 - val_accuracy: 0.9753 - val_top-2-accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "12/12 [==============================] - 103s 9s/step - loss: 0.0263 - accuracy: 0.9907 - top-2-accuracy: 0.9986 - val_loss: 0.1020 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9877\n",
      "Epoch 85/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0291 - accuracy: 0.9901 - top-2-accuracy: 0.9997 - val_loss: 0.1432 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9907\n",
      "Epoch 86/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0336 - accuracy: 0.9897 - top-2-accuracy: 0.9990 - val_loss: 0.1684 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9938\n",
      "Epoch 87/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0754 - accuracy: 0.9753 - top-2-accuracy: 0.9976 - val_loss: 0.1782 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9877\n",
      "Epoch 88/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0717 - accuracy: 0.9798 - top-2-accuracy: 0.9976 - val_loss: 0.2290 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9877\n",
      "Epoch 89/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0474 - accuracy: 0.9825 - top-2-accuracy: 0.9986 - val_loss: 0.0916 - val_accuracy: 0.9846 - val_top-2-accuracy: 0.9907\n",
      "Epoch 90/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0310 - accuracy: 0.9890 - top-2-accuracy: 0.9997 - val_loss: 0.0817 - val_accuracy: 0.9815 - val_top-2-accuracy: 0.9938\n",
      "Epoch 91/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0404 - accuracy: 0.9856 - top-2-accuracy: 0.9983 - val_loss: 0.1482 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9969\n",
      "Epoch 92/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0398 - accuracy: 0.9870 - top-2-accuracy: 0.9990 - val_loss: 0.1355 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9907\n",
      "Epoch 93/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0667 - accuracy: 0.9835 - top-2-accuracy: 0.9993 - val_loss: 0.0861 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9938\n",
      "Epoch 94/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0528 - accuracy: 0.9835 - top-2-accuracy: 0.9973 - val_loss: 0.1138 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9969\n",
      "Epoch 95/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0238 - accuracy: 0.9918 - top-2-accuracy: 0.9997 - val_loss: 0.0491 - val_accuracy: 0.9753 - val_top-2-accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0159 - accuracy: 0.9945 - top-2-accuracy: 0.9986 - val_loss: 0.0563 - val_accuracy: 0.9815 - val_top-2-accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0190 - accuracy: 0.9935 - top-2-accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9938\n",
      "Epoch 98/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0288 - accuracy: 0.9904 - top-2-accuracy: 0.9979 - val_loss: 0.0741 - val_accuracy: 0.9846 - val_top-2-accuracy: 0.9938\n",
      "Epoch 99/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0507 - accuracy: 0.9866 - top-2-accuracy: 0.9993 - val_loss: 0.0753 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9969\n",
      "Epoch 100/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0527 - accuracy: 0.9852 - top-2-accuracy: 0.9986 - val_loss: 0.0932 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9969\n",
      "Epoch 101/200\n",
      "12/12 [==============================] - 103s 9s/step - loss: 0.0323 - accuracy: 0.9883 - top-2-accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9969\n",
      "Epoch 102/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0280 - accuracy: 0.9928 - top-2-accuracy: 1.0000 - val_loss: 0.0912 - val_accuracy: 0.9815 - val_top-2-accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0601 - accuracy: 0.9825 - top-2-accuracy: 0.9976 - val_loss: 0.0988 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9969\n",
      "Epoch 104/200\n",
      "12/12 [==============================] - 102s 8s/step - loss: 0.0459 - accuracy: 0.9832 - top-2-accuracy: 0.9976 - val_loss: 0.1816 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9969\n",
      "Epoch 105/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0364 - accuracy: 0.9883 - top-2-accuracy: 0.9993 - val_loss: 0.0869 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9969\n",
      "Epoch 106/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0482 - accuracy: 0.9842 - top-2-accuracy: 0.9986 - val_loss: 0.1124 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9969\n",
      "Epoch 107/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0471 - accuracy: 0.9863 - top-2-accuracy: 0.9990 - val_loss: 0.0671 - val_accuracy: 0.9784 - val_top-2-accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0235 - accuracy: 0.9918 - top-2-accuracy: 0.9997 - val_loss: 0.1001 - val_accuracy: 0.9815 - val_top-2-accuracy: 0.9969\n",
      "Epoch 109/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0232 - accuracy: 0.9914 - top-2-accuracy: 0.9997 - val_loss: 0.0558 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9969\n",
      "Epoch 110/200\n",
      "12/12 [==============================] - 103s 9s/step - loss: 0.0193 - accuracy: 0.9942 - top-2-accuracy: 0.9997 - val_loss: 0.0590 - val_accuracy: 0.9846 - val_top-2-accuracy: 0.9969\n",
      "Epoch 111/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0201 - accuracy: 0.9925 - top-2-accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 0.9784 - val_top-2-accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0180 - accuracy: 0.9959 - top-2-accuracy: 0.9997 - val_loss: 0.0486 - val_accuracy: 0.9877 - val_top-2-accuracy: 0.9938\n",
      "Epoch 113/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0193 - accuracy: 0.9931 - top-2-accuracy: 0.9997 - val_loss: 0.1010 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9969\n",
      "Epoch 114/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0293 - accuracy: 0.9901 - top-2-accuracy: 0.9990 - val_loss: 0.0984 - val_accuracy: 0.9753 - val_top-2-accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0319 - accuracy: 0.9890 - top-2-accuracy: 0.9990 - val_loss: 0.0721 - val_accuracy: 0.9753 - val_top-2-accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "12/12 [==============================] - 102s 9s/step - loss: 0.0307 - accuracy: 0.9904 - top-2-accuracy: 0.9990 - val_loss: 0.0935 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9969\n",
      "Epoch 117/200\n",
      "12/12 [==============================] - 101s 8s/step - loss: 0.0351 - accuracy: 0.9901 - top-2-accuracy: 0.9986 - val_loss: 0.0680 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9969\n",
      "Epoch 118/200\n",
      "12/12 [==============================] - 103s 9s/step - loss: 0.0267 - accuracy: 0.9928 - top-2-accuracy: 0.9997 - val_loss: 0.0942 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9938\n",
      "Epoch 119/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0229 - accuracy: 0.9911 - top-2-accuracy: 0.9990 - val_loss: 0.0651 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9969\n",
      "Epoch 120/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0274 - accuracy: 0.9911 - top-2-accuracy: 0.9997 - val_loss: 0.0885 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9969\n",
      "Epoch 121/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0220 - accuracy: 0.9925 - top-2-accuracy: 0.9997 - val_loss: 0.1126 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9969\n",
      "Epoch 122/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0216 - accuracy: 0.9914 - top-2-accuracy: 0.9997 - val_loss: 0.0688 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9938\n",
      "Epoch 123/200\n",
      "12/12 [==============================] - 103s 9s/step - loss: 0.0358 - accuracy: 0.9873 - top-2-accuracy: 1.0000 - val_loss: 0.1645 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9907\n",
      "Epoch 124/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0386 - accuracy: 0.9856 - top-2-accuracy: 0.9993 - val_loss: 0.0785 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9969\n",
      "Epoch 125/200\n",
      "12/12 [==============================] - 104s 9s/step - loss: 0.0449 - accuracy: 0.9873 - top-2-accuracy: 1.0000 - val_loss: 0.1441 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9907\n",
      "Epoch 126/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0272 - accuracy: 0.9911 - top-2-accuracy: 0.9993 - val_loss: 0.1085 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9969\n",
      "Epoch 127/200\n",
      "12/12 [==============================] - 103s 9s/step - loss: 0.0192 - accuracy: 0.9942 - top-2-accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9969\n",
      "Epoch 128/200\n",
      "12/12 [==============================] - 103s 9s/step - loss: 0.0343 - accuracy: 0.9914 - top-2-accuracy: 0.9993 - val_loss: 0.0966 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9938\n",
      "Epoch 129/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0275 - accuracy: 0.9925 - top-2-accuracy: 0.9993 - val_loss: 0.1376 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9907\n",
      "Epoch 130/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0287 - accuracy: 0.9911 - top-2-accuracy: 0.9986 - val_loss: 0.1158 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9938\n",
      "Epoch 131/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0237 - accuracy: 0.9918 - top-2-accuracy: 0.9993 - val_loss: 0.1443 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9938\n",
      "Epoch 132/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0221 - accuracy: 0.9911 - top-2-accuracy: 0.9983 - val_loss: 0.1219 - val_accuracy: 0.9846 - val_top-2-accuracy: 0.9938\n",
      "Epoch 133/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0403 - accuracy: 0.9897 - top-2-accuracy: 0.9990 - val_loss: 0.0796 - val_accuracy: 0.9784 - val_top-2-accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0374 - accuracy: 0.9887 - top-2-accuracy: 0.9990 - val_loss: 0.1170 - val_accuracy: 0.9815 - val_top-2-accuracy: 0.9969\n",
      "Epoch 135/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0406 - accuracy: 0.9890 - top-2-accuracy: 0.9979 - val_loss: 0.0907 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9969\n",
      "Epoch 136/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0344 - accuracy: 0.9873 - top-2-accuracy: 1.0000 - val_loss: 0.0853 - val_accuracy: 0.9784 - val_top-2-accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0580 - accuracy: 0.9835 - top-2-accuracy: 0.9976 - val_loss: 0.1277 - val_accuracy: 0.9846 - val_top-2-accuracy: 0.9969\n",
      "Epoch 138/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0326 - accuracy: 0.9887 - top-2-accuracy: 0.9983 - val_loss: 0.1158 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9969\n",
      "Epoch 139/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0295 - accuracy: 0.9907 - top-2-accuracy: 0.9993 - val_loss: 0.1946 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 140/200\n",
      "12/12 [==============================] - 111s 9s/step - loss: 0.0419 - accuracy: 0.9883 - top-2-accuracy: 0.9983 - val_loss: 0.0979 - val_accuracy: 0.9815 - val_top-2-accuracy: 0.9907\n",
      "Epoch 141/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0351 - accuracy: 0.9897 - top-2-accuracy: 0.9993 - val_loss: 0.0971 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9907\n",
      "Epoch 142/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0499 - accuracy: 0.9863 - top-2-accuracy: 0.9983 - val_loss: 0.0921 - val_accuracy: 0.9660 - val_top-2-accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0311 - accuracy: 0.9890 - top-2-accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9877\n",
      "Epoch 144/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0445 - accuracy: 0.9856 - top-2-accuracy: 0.9986 - val_loss: 0.1536 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9907\n",
      "Epoch 145/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0306 - accuracy: 0.9904 - top-2-accuracy: 0.9997 - val_loss: 0.1487 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9938\n",
      "Epoch 146/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0330 - accuracy: 0.9877 - top-2-accuracy: 0.9993 - val_loss: 0.0850 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9938\n",
      "Epoch 147/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0394 - accuracy: 0.9887 - top-2-accuracy: 0.9979 - val_loss: 0.1244 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9907\n",
      "Epoch 148/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0236 - accuracy: 0.9914 - top-2-accuracy: 0.9993 - val_loss: 0.0891 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9877\n",
      "Epoch 149/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0220 - accuracy: 0.9918 - top-2-accuracy: 0.9997 - val_loss: 0.0696 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9938\n",
      "Epoch 150/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0255 - accuracy: 0.9931 - top-2-accuracy: 0.9997 - val_loss: 0.0619 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9969\n",
      "Epoch 151/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0212 - accuracy: 0.9928 - top-2-accuracy: 0.9997 - val_loss: 0.1691 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9907\n",
      "Epoch 152/200\n",
      "12/12 [==============================] - 105s 9s/step - loss: 0.0271 - accuracy: 0.9925 - top-2-accuracy: 0.9990 - val_loss: 0.1233 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9907\n",
      "Epoch 153/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0216 - accuracy: 0.9931 - top-2-accuracy: 0.9993 - val_loss: 0.0881 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9938\n",
      "Epoch 154/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0198 - accuracy: 0.9928 - top-2-accuracy: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9846 - val_top-2-accuracy: 0.9969\n",
      "Epoch 155/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0243 - accuracy: 0.9949 - top-2-accuracy: 0.9993 - val_loss: 0.0445 - val_accuracy: 0.9815 - val_top-2-accuracy: 0.9969\n",
      "Epoch 156/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0232 - accuracy: 0.9942 - top-2-accuracy: 0.9990 - val_loss: 0.1245 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9907\n",
      "Epoch 157/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0307 - accuracy: 0.9897 - top-2-accuracy: 0.9990 - val_loss: 0.1719 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9877\n",
      "Epoch 158/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0267 - accuracy: 0.9904 - top-2-accuracy: 0.9997 - val_loss: 0.1371 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9907\n",
      "Epoch 159/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0248 - accuracy: 0.9918 - top-2-accuracy: 0.9993 - val_loss: 0.1397 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9938\n",
      "Epoch 160/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0270 - accuracy: 0.9911 - top-2-accuracy: 0.9986 - val_loss: 0.1508 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9907\n",
      "Epoch 161/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0256 - accuracy: 0.9935 - top-2-accuracy: 0.9990 - val_loss: 0.2244 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9938\n",
      "Epoch 162/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0274 - accuracy: 0.9918 - top-2-accuracy: 0.9990 - val_loss: 0.1539 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9907\n",
      "Epoch 163/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0287 - accuracy: 0.9907 - top-2-accuracy: 0.9993 - val_loss: 0.1686 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9938\n",
      "Epoch 164/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0305 - accuracy: 0.9894 - top-2-accuracy: 0.9997 - val_loss: 0.1504 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9969\n",
      "Epoch 165/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0708 - accuracy: 0.9842 - top-2-accuracy: 0.9973 - val_loss: 0.1937 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9907\n",
      "Epoch 166/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0508 - accuracy: 0.9856 - top-2-accuracy: 0.9986 - val_loss: 0.1795 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9877\n",
      "Epoch 167/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0549 - accuracy: 0.9835 - top-2-accuracy: 0.9983 - val_loss: 0.1362 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9938\n",
      "Epoch 168/200\n",
      "12/12 [==============================] - 111s 9s/step - loss: 0.0338 - accuracy: 0.9897 - top-2-accuracy: 0.9983 - val_loss: 0.1045 - val_accuracy: 0.9660 - val_top-2-accuracy: 0.9938\n",
      "Epoch 169/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0278 - accuracy: 0.9901 - top-2-accuracy: 0.9993 - val_loss: 0.0945 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9938\n",
      "Epoch 170/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0260 - accuracy: 0.9928 - top-2-accuracy: 0.9986 - val_loss: 0.1671 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9938\n",
      "Epoch 171/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0319 - accuracy: 0.9907 - top-2-accuracy: 0.9993 - val_loss: 0.0912 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9938\n",
      "Epoch 172/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0197 - accuracy: 0.9942 - top-2-accuracy: 0.9986 - val_loss: 0.1243 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9969\n",
      "Epoch 173/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0151 - accuracy: 0.9952 - top-2-accuracy: 0.9997 - val_loss: 0.2353 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9938\n",
      "Epoch 174/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0264 - accuracy: 0.9928 - top-2-accuracy: 0.9990 - val_loss: 0.1660 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9938\n",
      "Epoch 175/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0512 - accuracy: 0.9852 - top-2-accuracy: 0.9969 - val_loss: 0.1892 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9938\n",
      "Epoch 176/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0436 - accuracy: 0.9873 - top-2-accuracy: 0.9997 - val_loss: 0.1168 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9877\n",
      "Epoch 177/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0608 - accuracy: 0.9777 - top-2-accuracy: 0.9976 - val_loss: 0.1868 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9877\n",
      "Epoch 178/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0458 - accuracy: 0.9849 - top-2-accuracy: 0.9993 - val_loss: 0.1086 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9846\n",
      "Epoch 179/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0281 - accuracy: 0.9914 - top-2-accuracy: 0.9990 - val_loss: 0.1336 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9938\n",
      "Epoch 180/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0101 - accuracy: 0.9959 - top-2-accuracy: 1.0000 - val_loss: 0.1324 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9907\n",
      "Epoch 181/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0149 - accuracy: 0.9952 - top-2-accuracy: 0.9997 - val_loss: 0.1177 - val_accuracy: 0.9722 - val_top-2-accuracy: 0.9969\n",
      "Epoch 182/200\n",
      "12/12 [==============================] - 112s 9s/step - loss: 0.0126 - accuracy: 0.9955 - top-2-accuracy: 1.0000 - val_loss: 0.1362 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9969\n",
      "Epoch 183/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0116 - accuracy: 0.9955 - top-2-accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9938\n",
      "Epoch 184/200\n",
      "12/12 [==============================] - 114s 10s/step - loss: 0.0136 - accuracy: 0.9962 - top-2-accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9815 - val_top-2-accuracy: 0.9969\n",
      "Epoch 185/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0376 - accuracy: 0.9870 - top-2-accuracy: 1.0000 - val_loss: 0.2582 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9938\n",
      "Epoch 186/200\n",
      "12/12 [==============================] - 108s 9s/step - loss: 0.0516 - accuracy: 0.9859 - top-2-accuracy: 0.9990 - val_loss: 0.1477 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9938\n",
      "Epoch 187/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0241 - accuracy: 0.9911 - top-2-accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9630 - val_top-2-accuracy: 0.9969\n",
      "Epoch 188/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0196 - accuracy: 0.9928 - top-2-accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9815 - val_top-2-accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "12/12 [==============================] - 106s 9s/step - loss: 0.0128 - accuracy: 0.9962 - top-2-accuracy: 0.9997 - val_loss: 0.2906 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9907\n",
      "Epoch 190/200\n",
      "12/12 [==============================] - 111s 9s/step - loss: 0.0263 - accuracy: 0.9901 - top-2-accuracy: 0.9990 - val_loss: 0.1270 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9969\n",
      "Epoch 191/200\n",
      "12/12 [==============================] - 107s 9s/step - loss: 0.0293 - accuracy: 0.9904 - top-2-accuracy: 0.9997 - val_loss: 0.1009 - val_accuracy: 0.9815 - val_top-2-accuracy: 0.9969\n",
      "Epoch 192/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0343 - accuracy: 0.9907 - top-2-accuracy: 0.9993 - val_loss: 0.0821 - val_accuracy: 0.9691 - val_top-2-accuracy: 0.9969\n",
      "Epoch 193/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0270 - accuracy: 0.9931 - top-2-accuracy: 0.9983 - val_loss: 0.0750 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9969\n",
      "Epoch 194/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0104 - accuracy: 0.9966 - top-2-accuracy: 1.0000 - val_loss: 0.0526 - val_accuracy: 0.9846 - val_top-2-accuracy: 0.9938\n",
      "Epoch 195/200\n",
      "12/12 [==============================] - 111s 9s/step - loss: 0.0099 - accuracy: 0.9973 - top-2-accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9815 - val_top-2-accuracy: 0.9938\n",
      "Epoch 196/200\n",
      "12/12 [==============================] - 111s 9s/step - loss: 0.0094 - accuracy: 0.9976 - top-2-accuracy: 0.9997 - val_loss: 0.0679 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9969\n",
      "Epoch 197/200\n",
      "12/12 [==============================] - 110s 9s/step - loss: 0.0078 - accuracy: 0.9986 - top-2-accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9846 - val_top-2-accuracy: 0.9969\n",
      "Epoch 198/200\n",
      "12/12 [==============================] - 112s 9s/step - loss: 0.0099 - accuracy: 0.9966 - top-2-accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9784 - val_top-2-accuracy: 0.9907\n",
      "Epoch 199/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0211 - accuracy: 0.9955 - top-2-accuracy: 0.9997 - val_loss: 0.1686 - val_accuracy: 0.9753 - val_top-2-accuracy: 0.9907\n",
      "Epoch 200/200\n",
      "12/12 [==============================] - 109s 9s/step - loss: 0.0189 - accuracy: 0.9935 - top-2-accuracy: 1.0000 - val_loss: 0.2411 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9938\n",
      "26/26 [==============================] - 13s 489ms/step - loss: 0.0466 - accuracy: 0.9889 - top-2-accuracy: 1.0000\n",
      "Test accuracy: 98.89%\n",
      "Test top 5 accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(2, name=\"top-2-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf623499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(2, name=\"top-2-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_2_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 2 accuracy: {round(top_2_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07cbfb8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "23/23 [==============================] - 23s 608ms/step - loss: 0.0649 - accuracy: 0.9784 - top-2-accuracy: 0.9983 - val_loss: 0.2787 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9907\n",
      "Epoch 2/150\n",
      "23/23 [==============================] - 12s 525ms/step - loss: 0.0608 - accuracy: 0.9849 - top-2-accuracy: 0.9979 - val_loss: 0.4750 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9846\n",
      "Epoch 3/150\n",
      "23/23 [==============================] - 12s 526ms/step - loss: 0.0967 - accuracy: 0.9746 - top-2-accuracy: 0.9966 - val_loss: 0.3697 - val_accuracy: 0.9074 - val_top-2-accuracy: 0.9753\n",
      "Epoch 4/150\n",
      "23/23 [==============================] - 12s 522ms/step - loss: 0.0638 - accuracy: 0.9791 - top-2-accuracy: 0.9969 - val_loss: 0.2596 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9815\n",
      "Epoch 5/150\n",
      "23/23 [==============================] - 12s 525ms/step - loss: 0.0423 - accuracy: 0.9870 - top-2-accuracy: 0.9990 - val_loss: 0.3433 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9846\n",
      "Epoch 6/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0264 - accuracy: 0.9928 - top-2-accuracy: 1.0000 - val_loss: 0.3240 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9815\n",
      "Epoch 7/150\n",
      "23/23 [==============================] - 12s 519ms/step - loss: 0.0525 - accuracy: 0.9846 - top-2-accuracy: 0.9990 - val_loss: 0.3302 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9815\n",
      "Epoch 8/150\n",
      "23/23 [==============================] - 12s 510ms/step - loss: 0.0514 - accuracy: 0.9849 - top-2-accuracy: 0.9986 - val_loss: 0.2994 - val_accuracy: 0.9290 - val_top-2-accuracy: 0.9877\n",
      "Epoch 9/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0493 - accuracy: 0.9835 - top-2-accuracy: 0.9983 - val_loss: 0.2553 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9846\n",
      "Epoch 10/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0546 - accuracy: 0.9828 - top-2-accuracy: 0.9983 - val_loss: 0.2873 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9846\n",
      "Epoch 11/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0487 - accuracy: 0.9859 - top-2-accuracy: 0.9986 - val_loss: 0.3468 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9722\n",
      "Epoch 12/150\n",
      "23/23 [==============================] - 12s 514ms/step - loss: 0.0794 - accuracy: 0.9780 - top-2-accuracy: 0.9990 - val_loss: 0.3251 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9907\n",
      "Epoch 13/150\n",
      "23/23 [==============================] - 12s 516ms/step - loss: 0.0511 - accuracy: 0.9811 - top-2-accuracy: 0.9990 - val_loss: 0.3199 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9877\n",
      "Epoch 14/150\n",
      "23/23 [==============================] - 12s 514ms/step - loss: 0.0790 - accuracy: 0.9811 - top-2-accuracy: 0.9986 - val_loss: 0.2239 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9784\n",
      "Epoch 15/150\n",
      "23/23 [==============================] - 12s 516ms/step - loss: 0.0493 - accuracy: 0.9846 - top-2-accuracy: 0.9990 - val_loss: 0.3879 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9877\n",
      "Epoch 16/150\n",
      "23/23 [==============================] - 12s 517ms/step - loss: 0.0763 - accuracy: 0.9791 - top-2-accuracy: 0.9979 - val_loss: 0.3650 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9815\n",
      "Epoch 17/150\n",
      "23/23 [==============================] - 12s 511ms/step - loss: 0.1209 - accuracy: 0.9750 - top-2-accuracy: 0.9955 - val_loss: 0.2703 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9907\n",
      "Epoch 18/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0713 - accuracy: 0.9777 - top-2-accuracy: 0.9959 - val_loss: 0.3996 - val_accuracy: 0.9105 - val_top-2-accuracy: 0.9691\n",
      "Epoch 19/150\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 0.0601 - accuracy: 0.9839 - top-2-accuracy: 0.9976 - val_loss: 0.2544 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9877\n",
      "Epoch 20/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0428 - accuracy: 0.9863 - top-2-accuracy: 0.9979 - val_loss: 0.3005 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9877\n",
      "Epoch 21/150\n",
      "23/23 [==============================] - 12s 517ms/step - loss: 0.0599 - accuracy: 0.9863 - top-2-accuracy: 0.9979 - val_loss: 0.3265 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9815\n",
      "Epoch 22/150\n",
      "23/23 [==============================] - 12s 516ms/step - loss: 0.0586 - accuracy: 0.9849 - top-2-accuracy: 0.9979 - val_loss: 0.2365 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9846\n",
      "Epoch 23/150\n",
      "23/23 [==============================] - 12s 518ms/step - loss: 0.0438 - accuracy: 0.9870 - top-2-accuracy: 0.9986 - val_loss: 0.3773 - val_accuracy: 0.9136 - val_top-2-accuracy: 0.9753\n",
      "Epoch 24/150\n",
      "23/23 [==============================] - 12s 517ms/step - loss: 0.0540 - accuracy: 0.9849 - top-2-accuracy: 0.9979 - val_loss: 0.2874 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9784\n",
      "Epoch 25/150\n",
      "23/23 [==============================] - 12s 520ms/step - loss: 0.0423 - accuracy: 0.9873 - top-2-accuracy: 0.9986 - val_loss: 0.3028 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9846\n",
      "Epoch 26/150\n",
      "23/23 [==============================] - 12s 518ms/step - loss: 0.0318 - accuracy: 0.9897 - top-2-accuracy: 0.9997 - val_loss: 0.3025 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9938\n",
      "Epoch 27/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0326 - accuracy: 0.9883 - top-2-accuracy: 0.9990 - val_loss: 0.3180 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9815\n",
      "Epoch 28/150\n",
      "23/23 [==============================] - 12s 520ms/step - loss: 0.0411 - accuracy: 0.9887 - top-2-accuracy: 0.9997 - val_loss: 0.3265 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9938\n",
      "Epoch 29/150\n",
      "23/23 [==============================] - 12s 514ms/step - loss: 0.0400 - accuracy: 0.9894 - top-2-accuracy: 0.9990 - val_loss: 0.2398 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9846\n",
      "Epoch 30/150\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 0.0385 - accuracy: 0.9897 - top-2-accuracy: 0.9983 - val_loss: 0.2530 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9877\n",
      "Epoch 31/150\n",
      "23/23 [==============================] - 12s 509ms/step - loss: 0.0422 - accuracy: 0.9904 - top-2-accuracy: 0.9990 - val_loss: 0.2509 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9877\n",
      "Epoch 32/150\n",
      "23/23 [==============================] - 12s 514ms/step - loss: 0.0276 - accuracy: 0.9907 - top-2-accuracy: 0.9990 - val_loss: 0.2143 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9877\n",
      "Epoch 33/150\n",
      "23/23 [==============================] - 12s 525ms/step - loss: 0.0409 - accuracy: 0.9866 - top-2-accuracy: 0.9993 - val_loss: 0.1479 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9846\n",
      "Epoch 34/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0279 - accuracy: 0.9914 - top-2-accuracy: 0.9997 - val_loss: 0.3019 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9846\n",
      "Epoch 35/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0232 - accuracy: 0.9921 - top-2-accuracy: 1.0000 - val_loss: 0.2654 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9846\n",
      "Epoch 36/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0268 - accuracy: 0.9925 - top-2-accuracy: 0.9993 - val_loss: 0.3001 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9815\n",
      "Epoch 37/150\n",
      "23/23 [==============================] - 12s 510ms/step - loss: 0.0570 - accuracy: 0.9835 - top-2-accuracy: 0.9986 - val_loss: 0.4769 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9784\n",
      "Epoch 38/150\n",
      "23/23 [==============================] - 12s 513ms/step - loss: 0.0919 - accuracy: 0.9767 - top-2-accuracy: 0.9973 - val_loss: 0.3291 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9753\n",
      "Epoch 39/150\n",
      "23/23 [==============================] - 12s 516ms/step - loss: 0.0552 - accuracy: 0.9822 - top-2-accuracy: 0.9979 - val_loss: 0.2218 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9753\n",
      "Epoch 40/150\n",
      "23/23 [==============================] - 12s 522ms/step - loss: 0.0649 - accuracy: 0.9791 - top-2-accuracy: 0.9983 - val_loss: 0.3335 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9753\n",
      "Epoch 41/150\n",
      "23/23 [==============================] - 12s 521ms/step - loss: 0.0324 - accuracy: 0.9887 - top-2-accuracy: 0.9993 - val_loss: 0.2446 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9846\n",
      "Epoch 42/150\n",
      "23/23 [==============================] - 12s 517ms/step - loss: 0.0269 - accuracy: 0.9907 - top-2-accuracy: 0.9993 - val_loss: 0.3148 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9784\n",
      "Epoch 43/150\n",
      "23/23 [==============================] - 12s 511ms/step - loss: 0.0420 - accuracy: 0.9873 - top-2-accuracy: 0.9986 - val_loss: 0.2137 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9877\n",
      "Epoch 44/150\n",
      "23/23 [==============================] - 12s 509ms/step - loss: 0.0553 - accuracy: 0.9842 - top-2-accuracy: 0.9973 - val_loss: 0.3116 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9784\n",
      "Epoch 45/150\n",
      "23/23 [==============================] - 12s 514ms/step - loss: 0.0304 - accuracy: 0.9901 - top-2-accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9784\n",
      "Epoch 46/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0327 - accuracy: 0.9904 - top-2-accuracy: 0.9986 - val_loss: 0.2850 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9815\n",
      "Epoch 47/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0213 - accuracy: 0.9931 - top-2-accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9784\n",
      "Epoch 48/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0336 - accuracy: 0.9911 - top-2-accuracy: 0.9990 - val_loss: 0.3548 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9722\n",
      "Epoch 49/150\n",
      "23/23 [==============================] - 12s 514ms/step - loss: 0.0438 - accuracy: 0.9863 - top-2-accuracy: 0.9983 - val_loss: 0.2198 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9877\n",
      "Epoch 50/150\n",
      "23/23 [==============================] - 12s 542ms/step - loss: 0.0481 - accuracy: 0.9880 - top-2-accuracy: 0.9979 - val_loss: 0.3688 - val_accuracy: 0.9198 - val_top-2-accuracy: 0.9753\n",
      "Epoch 51/150\n",
      "23/23 [==============================] - 13s 562ms/step - loss: 0.0729 - accuracy: 0.9804 - top-2-accuracy: 0.9973 - val_loss: 0.2485 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9753\n",
      "Epoch 52/150\n",
      "23/23 [==============================] - 13s 558ms/step - loss: 0.0277 - accuracy: 0.9897 - top-2-accuracy: 0.9997 - val_loss: 0.2821 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9722\n",
      "Epoch 53/150\n",
      "23/23 [==============================] - 12s 533ms/step - loss: 0.0238 - accuracy: 0.9931 - top-2-accuracy: 0.9993 - val_loss: 0.3243 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9660\n",
      "Epoch 54/150\n",
      "23/23 [==============================] - 13s 556ms/step - loss: 0.0163 - accuracy: 0.9931 - top-2-accuracy: 0.9997 - val_loss: 0.2592 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9846\n",
      "Epoch 55/150\n",
      "23/23 [==============================] - 12s 543ms/step - loss: 0.0113 - accuracy: 0.9966 - top-2-accuracy: 0.9997 - val_loss: 0.3834 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9846\n",
      "Epoch 56/150\n",
      "23/23 [==============================] - 12s 520ms/step - loss: 0.0244 - accuracy: 0.9918 - top-2-accuracy: 0.9997 - val_loss: 0.4070 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9907\n",
      "Epoch 57/150\n",
      "23/23 [==============================] - 12s 510ms/step - loss: 0.0466 - accuracy: 0.9873 - top-2-accuracy: 0.9986 - val_loss: 0.2141 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9877\n",
      "Epoch 58/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0476 - accuracy: 0.9887 - top-2-accuracy: 0.9986 - val_loss: 0.3431 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9907\n",
      "Epoch 59/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0369 - accuracy: 0.9894 - top-2-accuracy: 1.0000 - val_loss: 0.3309 - val_accuracy: 0.9290 - val_top-2-accuracy: 0.9846\n",
      "Epoch 60/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0444 - accuracy: 0.9880 - top-2-accuracy: 0.9986 - val_loss: 0.2562 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9877\n",
      "Epoch 61/150\n",
      "23/23 [==============================] - 12s 516ms/step - loss: 0.0389 - accuracy: 0.9897 - top-2-accuracy: 0.9976 - val_loss: 0.2446 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9877\n",
      "Epoch 62/150\n",
      "23/23 [==============================] - 12s 517ms/step - loss: 0.0254 - accuracy: 0.9925 - top-2-accuracy: 0.9990 - val_loss: 0.3026 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9846\n",
      "Epoch 63/150\n",
      "23/23 [==============================] - 12s 514ms/step - loss: 0.0174 - accuracy: 0.9945 - top-2-accuracy: 0.9997 - val_loss: 0.3414 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9784\n",
      "Epoch 64/150\n",
      "23/23 [==============================] - 12s 511ms/step - loss: 0.0354 - accuracy: 0.9890 - top-2-accuracy: 0.9993 - val_loss: 0.3194 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9784\n",
      "Epoch 65/150\n",
      "23/23 [==============================] - 12s 515ms/step - loss: 0.0288 - accuracy: 0.9894 - top-2-accuracy: 0.9990 - val_loss: 0.3295 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9784\n",
      "Epoch 66/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0418 - accuracy: 0.9887 - top-2-accuracy: 0.9986 - val_loss: 0.3904 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9846\n",
      "Epoch 67/150\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 0.0602 - accuracy: 0.9863 - top-2-accuracy: 0.9986 - val_loss: 0.1900 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9815\n",
      "Epoch 68/150\n",
      "23/23 [==============================] - 12s 510ms/step - loss: 0.0527 - accuracy: 0.9846 - top-2-accuracy: 0.9986 - val_loss: 0.3033 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9815\n",
      "Epoch 69/150\n",
      "23/23 [==============================] - 12s 517ms/step - loss: 0.0742 - accuracy: 0.9822 - top-2-accuracy: 0.9983 - val_loss: 0.2986 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9753\n",
      "Epoch 70/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0310 - accuracy: 0.9890 - top-2-accuracy: 0.9997 - val_loss: 0.2887 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9815\n",
      "Epoch 71/150\n",
      "23/23 [==============================] - 12s 514ms/step - loss: 0.0309 - accuracy: 0.9907 - top-2-accuracy: 0.9993 - val_loss: 0.2402 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9846\n",
      "Epoch 72/150\n",
      "23/23 [==============================] - 12s 517ms/step - loss: 0.0362 - accuracy: 0.9914 - top-2-accuracy: 0.9986 - val_loss: 0.1950 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9815\n",
      "Epoch 73/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0269 - accuracy: 0.9904 - top-2-accuracy: 0.9993 - val_loss: 0.1979 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9877\n",
      "Epoch 74/150\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 0.0377 - accuracy: 0.9897 - top-2-accuracy: 0.9986 - val_loss: 0.2062 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9877\n",
      "Epoch 75/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0183 - accuracy: 0.9931 - top-2-accuracy: 0.9997 - val_loss: 0.2599 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9846\n",
      "Epoch 76/150\n",
      "23/23 [==============================] - 12s 516ms/step - loss: 0.0338 - accuracy: 0.9925 - top-2-accuracy: 0.9993 - val_loss: 0.2934 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9846\n",
      "Epoch 77/150\n",
      "23/23 [==============================] - 12s 517ms/step - loss: 0.0352 - accuracy: 0.9894 - top-2-accuracy: 0.9993 - val_loss: 0.2125 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9846\n",
      "Epoch 78/150\n",
      "23/23 [==============================] - 12s 509ms/step - loss: 0.0370 - accuracy: 0.9873 - top-2-accuracy: 0.9993 - val_loss: 0.2161 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9938\n",
      "Epoch 79/150\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 0.0614 - accuracy: 0.9828 - top-2-accuracy: 0.9969 - val_loss: 0.3321 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9784\n",
      "Epoch 80/150\n",
      "23/23 [==============================] - 12s 511ms/step - loss: 0.0436 - accuracy: 0.9880 - top-2-accuracy: 0.9986 - val_loss: 0.2523 - val_accuracy: 0.9290 - val_top-2-accuracy: 0.9722\n",
      "Epoch 81/150\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 0.0380 - accuracy: 0.9904 - top-2-accuracy: 0.9986 - val_loss: 0.2607 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9907\n",
      "Epoch 82/150\n",
      "23/23 [==============================] - 12s 511ms/step - loss: 0.0263 - accuracy: 0.9897 - top-2-accuracy: 0.9997 - val_loss: 0.2624 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9907\n",
      "Epoch 83/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0616 - accuracy: 0.9846 - top-2-accuracy: 0.9979 - val_loss: 0.2988 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9753\n",
      "Epoch 84/150\n",
      "23/23 [==============================] - 12s 507ms/step - loss: 0.0296 - accuracy: 0.9880 - top-2-accuracy: 0.9990 - val_loss: 0.2751 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9907\n",
      "Epoch 85/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0294 - accuracy: 0.9918 - top-2-accuracy: 0.9990 - val_loss: 0.3730 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9753\n",
      "Epoch 86/150\n",
      "23/23 [==============================] - 12s 513ms/step - loss: 0.0533 - accuracy: 0.9839 - top-2-accuracy: 0.9986 - val_loss: 0.3151 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9846\n",
      "Epoch 87/150\n",
      "23/23 [==============================] - 12s 512ms/step - loss: 0.0448 - accuracy: 0.9877 - top-2-accuracy: 0.9990 - val_loss: 0.2577 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9907\n",
      "Epoch 88/150\n",
      "23/23 [==============================] - 12s 511ms/step - loss: 0.0462 - accuracy: 0.9866 - top-2-accuracy: 0.9986 - val_loss: 0.3287 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9722\n",
      "Epoch 89/150\n",
      "23/23 [==============================] - 12s 510ms/step - loss: 0.0416 - accuracy: 0.9890 - top-2-accuracy: 0.9983 - val_loss: 0.3309 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9722\n",
      "Epoch 90/150\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 0.0397 - accuracy: 0.9863 - top-2-accuracy: 0.9983 - val_loss: 0.2497 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9877\n",
      "Epoch 91/150\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 0.0187 - accuracy: 0.9935 - top-2-accuracy: 1.0000 - val_loss: 0.2514 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9815\n",
      "Epoch 92/150\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 0.0367 - accuracy: 0.9883 - top-2-accuracy: 0.9993 - val_loss: 0.3183 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9815\n",
      "Epoch 93/150\n",
      "23/23 [==============================] - 12s 508ms/step - loss: 0.0400 - accuracy: 0.9897 - top-2-accuracy: 0.9990 - val_loss: 0.3143 - val_accuracy: 0.9228 - val_top-2-accuracy: 0.9753\n",
      "Epoch 94/150\n",
      "23/23 [==============================] - 12s 505ms/step - loss: 0.0360 - accuracy: 0.9907 - top-2-accuracy: 0.9986 - val_loss: 0.2411 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9815\n",
      "Epoch 95/150\n",
      "23/23 [==============================] - 12s 510ms/step - loss: 0.0261 - accuracy: 0.9942 - top-2-accuracy: 0.9986 - val_loss: 0.2505 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9815\n",
      "Epoch 96/150\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 0.0149 - accuracy: 0.9955 - top-2-accuracy: 0.9990 - val_loss: 0.1585 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9907\n",
      "Epoch 97/150\n",
      "23/23 [==============================] - 12s 506ms/step - loss: 0.0080 - accuracy: 0.9966 - top-2-accuracy: 0.9997 - val_loss: 0.2039 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9815\n",
      "Epoch 98/150\n",
      "23/23 [==============================] - 11s 499ms/step - loss: 0.0229 - accuracy: 0.9931 - top-2-accuracy: 0.9990 - val_loss: 0.2559 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9846\n",
      "Epoch 99/150\n",
      "23/23 [==============================] - 12s 501ms/step - loss: 0.0147 - accuracy: 0.9955 - top-2-accuracy: 0.9993 - val_loss: 0.2722 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9815\n",
      "Epoch 100/150\n",
      "23/23 [==============================] - 11s 501ms/step - loss: 0.0269 - accuracy: 0.9931 - top-2-accuracy: 0.9986 - val_loss: 0.2319 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9846\n",
      "Epoch 101/150\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 0.0296 - accuracy: 0.9931 - top-2-accuracy: 1.0000 - val_loss: 0.2600 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9877\n",
      "Epoch 102/150\n",
      "23/23 [==============================] - 11s 499ms/step - loss: 0.0303 - accuracy: 0.9914 - top-2-accuracy: 0.9997 - val_loss: 0.2564 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9907\n",
      "Epoch 103/150\n",
      "23/23 [==============================] - 11s 495ms/step - loss: 0.0274 - accuracy: 0.9928 - top-2-accuracy: 0.9990 - val_loss: 0.2950 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9815\n",
      "Epoch 104/150\n",
      "23/23 [==============================] - 11s 500ms/step - loss: 0.0209 - accuracy: 0.9931 - top-2-accuracy: 0.9990 - val_loss: 0.2562 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9846\n",
      "Epoch 105/150\n",
      "23/23 [==============================] - 11s 495ms/step - loss: 0.0316 - accuracy: 0.9907 - top-2-accuracy: 0.9997 - val_loss: 0.3238 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9784\n",
      "Epoch 106/150\n",
      "23/23 [==============================] - 11s 494ms/step - loss: 0.0474 - accuracy: 0.9856 - top-2-accuracy: 0.9993 - val_loss: 0.2290 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9846\n",
      "Epoch 107/150\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0289 - accuracy: 0.9904 - top-2-accuracy: 0.9986 - val_loss: 0.2186 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9846\n",
      "Epoch 108/150\n",
      "23/23 [==============================] - 11s 493ms/step - loss: 0.0111 - accuracy: 0.9955 - top-2-accuracy: 1.0000 - val_loss: 0.2742 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9846\n",
      "Epoch 109/150\n",
      "23/23 [==============================] - 11s 496ms/step - loss: 0.0233 - accuracy: 0.9938 - top-2-accuracy: 1.0000 - val_loss: 0.2743 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9938\n",
      "Epoch 110/150\n",
      "23/23 [==============================] - 12s 504ms/step - loss: 0.0224 - accuracy: 0.9931 - top-2-accuracy: 0.9993 - val_loss: 0.1688 - val_accuracy: 0.9599 - val_top-2-accuracy: 0.9907\n",
      "Epoch 111/150\n",
      "23/23 [==============================] - 11s 489ms/step - loss: 0.0405 - accuracy: 0.9897 - top-2-accuracy: 0.9983 - val_loss: 0.3628 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9846\n",
      "Epoch 112/150\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0644 - accuracy: 0.9828 - top-2-accuracy: 0.9983 - val_loss: 0.2516 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9907\n",
      "Epoch 113/150\n",
      "23/23 [==============================] - 11s 488ms/step - loss: 0.0223 - accuracy: 0.9935 - top-2-accuracy: 0.9993 - val_loss: 0.2410 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9846\n",
      "Epoch 114/150\n",
      "23/23 [==============================] - 11s 486ms/step - loss: 0.0164 - accuracy: 0.9949 - top-2-accuracy: 0.9997 - val_loss: 0.2221 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9877\n",
      "Epoch 115/150\n",
      "23/23 [==============================] - 11s 488ms/step - loss: 0.0232 - accuracy: 0.9931 - top-2-accuracy: 1.0000 - val_loss: 0.2255 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9815\n",
      "Epoch 116/150\n",
      "23/23 [==============================] - 11s 486ms/step - loss: 0.0186 - accuracy: 0.9935 - top-2-accuracy: 1.0000 - val_loss: 0.1634 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9907\n",
      "Epoch 117/150\n",
      "23/23 [==============================] - 11s 493ms/step - loss: 0.0226 - accuracy: 0.9955 - top-2-accuracy: 0.9993 - val_loss: 0.1895 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9877\n",
      "Epoch 118/150\n",
      "23/23 [==============================] - 11s 489ms/step - loss: 0.0220 - accuracy: 0.9914 - top-2-accuracy: 0.9993 - val_loss: 0.2345 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9846\n",
      "Epoch 119/150\n",
      "23/23 [==============================] - 11s 495ms/step - loss: 0.0201 - accuracy: 0.9935 - top-2-accuracy: 0.9997 - val_loss: 0.2286 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9815\n",
      "Epoch 120/150\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0289 - accuracy: 0.9907 - top-2-accuracy: 0.9986 - val_loss: 0.2484 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9877\n",
      "Epoch 121/150\n",
      "23/23 [==============================] - 11s 489ms/step - loss: 0.0437 - accuracy: 0.9880 - top-2-accuracy: 0.9979 - val_loss: 0.3186 - val_accuracy: 0.9290 - val_top-2-accuracy: 0.9815\n",
      "Epoch 122/150\n",
      "23/23 [==============================] - 11s 496ms/step - loss: 0.0216 - accuracy: 0.9945 - top-2-accuracy: 1.0000 - val_loss: 0.1908 - val_accuracy: 0.9537 - val_top-2-accuracy: 0.9877\n",
      "Epoch 123/150\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0144 - accuracy: 0.9955 - top-2-accuracy: 0.9997 - val_loss: 0.3073 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9722\n",
      "Epoch 124/150\n",
      "23/23 [==============================] - 11s 498ms/step - loss: 0.0425 - accuracy: 0.9897 - top-2-accuracy: 0.9979 - val_loss: 0.2827 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9815\n",
      "Epoch 125/150\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0309 - accuracy: 0.9911 - top-2-accuracy: 0.9986 - val_loss: 0.2232 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9846\n",
      "Epoch 126/150\n",
      "23/23 [==============================] - 11s 487ms/step - loss: 0.0157 - accuracy: 0.9952 - top-2-accuracy: 0.9993 - val_loss: 0.1797 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9907\n",
      "Epoch 127/150\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0152 - accuracy: 0.9952 - top-2-accuracy: 0.9997 - val_loss: 0.2409 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9907\n",
      "Epoch 128/150\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0260 - accuracy: 0.9914 - top-2-accuracy: 1.0000 - val_loss: 0.2171 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9846\n",
      "Epoch 129/150\n",
      "23/23 [==============================] - 11s 495ms/step - loss: 0.0380 - accuracy: 0.9887 - top-2-accuracy: 0.9983 - val_loss: 0.2413 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9907\n",
      "Epoch 130/150\n",
      "23/23 [==============================] - 11s 490ms/step - loss: 0.0394 - accuracy: 0.9890 - top-2-accuracy: 0.9990 - val_loss: 0.1741 - val_accuracy: 0.9475 - val_top-2-accuracy: 0.9938\n",
      "Epoch 131/150\n",
      "23/23 [==============================] - 11s 497ms/step - loss: 0.0382 - accuracy: 0.9894 - top-2-accuracy: 0.9997 - val_loss: 0.1917 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9938\n",
      "Epoch 132/150\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0358 - accuracy: 0.9897 - top-2-accuracy: 0.9983 - val_loss: 0.2791 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9846\n",
      "Epoch 133/150\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0196 - accuracy: 0.9938 - top-2-accuracy: 0.9993 - val_loss: 0.2067 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9877\n",
      "Epoch 134/150\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0136 - accuracy: 0.9949 - top-2-accuracy: 1.0000 - val_loss: 0.2131 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9877\n",
      "Epoch 135/150\n",
      "23/23 [==============================] - 11s 487ms/step - loss: 0.0195 - accuracy: 0.9931 - top-2-accuracy: 0.9997 - val_loss: 0.3374 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9877\n",
      "Epoch 136/150\n",
      "23/23 [==============================] - 11s 493ms/step - loss: 0.0404 - accuracy: 0.9883 - top-2-accuracy: 0.9990 - val_loss: 0.2447 - val_accuracy: 0.9568 - val_top-2-accuracy: 0.9938\n",
      "Epoch 137/150\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0310 - accuracy: 0.9911 - top-2-accuracy: 0.9990 - val_loss: 0.2559 - val_accuracy: 0.9383 - val_top-2-accuracy: 0.9938\n",
      "Epoch 138/150\n",
      "23/23 [==============================] - 11s 489ms/step - loss: 0.0255 - accuracy: 0.9914 - top-2-accuracy: 0.9986 - val_loss: 0.2201 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9907\n",
      "Epoch 139/150\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0195 - accuracy: 0.9925 - top-2-accuracy: 0.9993 - val_loss: 0.3327 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9877\n",
      "Epoch 140/150\n",
      "23/23 [==============================] - 11s 484ms/step - loss: 0.0403 - accuracy: 0.9887 - top-2-accuracy: 0.9993 - val_loss: 0.2648 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9846\n",
      "Epoch 141/150\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0209 - accuracy: 0.9925 - top-2-accuracy: 0.9993 - val_loss: 0.2981 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9815\n",
      "Epoch 142/150\n",
      "23/23 [==============================] - 11s 493ms/step - loss: 0.0234 - accuracy: 0.9931 - top-2-accuracy: 0.9997 - val_loss: 0.3856 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9784\n",
      "Epoch 143/150\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0202 - accuracy: 0.9938 - top-2-accuracy: 0.9990 - val_loss: 0.2480 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9877\n",
      "Epoch 144/150\n",
      "23/23 [==============================] - 11s 495ms/step - loss: 0.0236 - accuracy: 0.9938 - top-2-accuracy: 0.9997 - val_loss: 0.2134 - val_accuracy: 0.9444 - val_top-2-accuracy: 0.9815\n",
      "Epoch 145/150\n",
      "23/23 [==============================] - 11s 492ms/step - loss: 0.0192 - accuracy: 0.9942 - top-2-accuracy: 0.9993 - val_loss: 0.2938 - val_accuracy: 0.9414 - val_top-2-accuracy: 0.9815\n",
      "Epoch 146/150\n",
      "23/23 [==============================] - 11s 489ms/step - loss: 0.0356 - accuracy: 0.9894 - top-2-accuracy: 0.9993 - val_loss: 0.3168 - val_accuracy: 0.9506 - val_top-2-accuracy: 0.9753\n",
      "Epoch 147/150\n",
      "23/23 [==============================] - 11s 496ms/step - loss: 0.0509 - accuracy: 0.9877 - top-2-accuracy: 0.9979 - val_loss: 0.3191 - val_accuracy: 0.9290 - val_top-2-accuracy: 0.9846\n",
      "Epoch 148/150\n",
      "23/23 [==============================] - 11s 494ms/step - loss: 0.0316 - accuracy: 0.9914 - top-2-accuracy: 0.9990 - val_loss: 0.3898 - val_accuracy: 0.9259 - val_top-2-accuracy: 0.9784\n",
      "Epoch 149/150\n",
      "23/23 [==============================] - 11s 491ms/step - loss: 0.0288 - accuracy: 0.9904 - top-2-accuracy: 0.9997 - val_loss: 0.3661 - val_accuracy: 0.9321 - val_top-2-accuracy: 0.9846\n",
      "Epoch 150/150\n",
      "23/23 [==============================] - 11s 500ms/step - loss: 0.0216 - accuracy: 0.9931 - top-2-accuracy: 0.9997 - val_loss: 0.2453 - val_accuracy: 0.9352 - val_top-2-accuracy: 0.9938\n",
      "26/26 [==============================] - 2s 93ms/step - loss: 0.1973 - accuracy: 0.9543 - top-2-accuracy: 0.9901\n",
      "Test accuracy: 95.43%\n",
      "Test top 2 accuracy: 99.01%\n"
     ]
    }
   ],
   "source": [
    "history = run_experiment(vit_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76b8f6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 2s 94ms/step - loss: 0.1973 - accuracy: 0.9543 - top-2-accuracy: 0.9901\n"
     ]
    }
   ],
   "source": [
    "_, accuracy, top_2_accuracy = vit_classifier.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "658897e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=y_test-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dccb33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
